{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Copy of face-swap1-shaolu.ipynb","provenance":[{"file_id":"https://github.com/shaoanlu/fewshot-face-translation-GAN/blob/master/colab_demo.ipynb","timestamp":1579303683640}],"collapsed_sections":["drpzzGCgl0AW"],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"}},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"z1WtuizOlz-S"},"source":["# Welcome\n","\n","####This is a Colab notebook for photo translation using GAN\n","####It is created and trained by Shaoanlu\n","####We have managed it fit our need and demostration\n"]},{"cell_type":"markdown","metadata":{"id":"oluj0S8ctunU","colab_type":"text"},"source":["## Clone git and download weight/model"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"iuSSeoFwlz-Y","outputId":"44d9656e-872c-4839-cdad-34c5247a2fb5","executionInfo":{"status":"ok","timestamp":1581977795470,"user_tz":-660,"elapsed":20215,"user":{"displayName":"Y Wang","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC_1743ZvXKz3VyvoMzNQtF6SVuixB99UzajSrbUg=s64","userId":"05996631538345338372"}},"colab":{"base_uri":"https://localhost:8080/","height":309}},"source":["!git clone --recursive https://github.com/shaoanlu/fewshot-face-translation-GAN.git"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Cloning into 'fewshot-face-translation-GAN'...\n","remote: Enumerating objects: 61, done.\u001b[K\n","remote: Counting objects:   1% (1/61)\u001b[K\rremote: Counting objects:   3% (2/61)\u001b[K\rremote: Counting objects:   4% (3/61)\u001b[K\rremote: Counting objects:   6% (4/61)\u001b[K\rremote: Counting objects:   8% (5/61)\u001b[K\rremote: Counting objects:   9% (6/61)\u001b[K\rremote: Counting objects:  11% (7/61)\u001b[K\rremote: Counting objects:  13% (8/61)\u001b[K\rremote: Counting objects:  14% (9/61)\u001b[K\rremote: Counting objects:  16% (10/61)\u001b[K\rremote: Counting objects:  18% (11/61)\u001b[K\rremote: Counting objects:  19% (12/61)\u001b[K\rremote: Counting objects:  21% (13/61)\u001b[K\rremote: Counting objects:  22% (14/61)\u001b[K\rremote: Counting objects:  24% (15/61)\u001b[K\rremote: Counting objects:  26% (16/61)\u001b[K\rremote: Counting objects:  27% (17/61)\u001b[K\rremote: Counting objects:  29% (18/61)\u001b[K\rremote: Counting objects:  31% (19/61)\u001b[K\rremote: Counting objects:  32% (20/61)\u001b[K\rremote: Counting objects:  34% (21/61)\u001b[K\rremote: Counting objects:  36% (22/61)\u001b[K\rremote: Counting objects:  37% (23/61)\u001b[K\rremote: Counting objects:  39% (24/61)\u001b[K\rremote: Counting objects:  40% (25/61)\u001b[K\rremote: Counting objects:  42% (26/61)\u001b[K\rremote: Counting objects:  44% (27/61)\u001b[K\rremote: Counting objects:  45% (28/61)\u001b[K\rremote: Counting objects:  47% (29/61)\u001b[K\rremote: Counting objects:  49% (30/61)\u001b[K\rremote: Counting objects:  50% (31/61)\u001b[K\rremote: Counting objects:  52% (32/61)\u001b[K\rremote: Counting objects:  54% (33/61)\u001b[K\rremote: Counting objects:  55% (34/61)\u001b[K\rremote: Counting objects:  57% (35/61)\u001b[K\rremote: Counting objects:  59% (36/61)\u001b[K\rremote: Counting objects:  60% (37/61)\u001b[K\rremote: Counting objects:  62% (38/61)\u001b[K\rremote: Counting objects:  63% (39/61)\u001b[K\rremote: Counting objects:  65% (40/61)\u001b[K\rremote: Counting objects:  67% (41/61)\u001b[K\rremote: Counting objects:  68% (42/61)\u001b[K\rremote: Counting objects:  70% (43/61)\u001b[K\rremote: Counting objects:  72% (44/61)\u001b[K\rremote: Counting objects:  73% (45/61)\u001b[K\rremote: Counting objects:  75% (46/61)\u001b[K\rremote: Counting objects:  77% (47/61)\u001b[K\rremote: Counting objects:  78% (48/61)\u001b[K\rremote: Counting objects:  80% (49/61)\u001b[K\rremote: Counting objects:  81% (50/61)\u001b[K\rremote: Counting objects:  83% (51/61)\u001b[K\rremote: Counting objects:  85% (52/61)\u001b[K\rremote: Counting objects:  86% (53/61)\u001b[K\rremote: Counting objects:  88% (54/61)\u001b[K\rremote: Counting objects:  90% (55/61)\u001b[K\rremote: Counting objects:  91% (56/61)\u001b[K\rremote: Counting objects:  93% (57/61)\u001b[K\rremote: Counting objects:  95% (58/61)\u001b[K\rremote: Counting objects:  96% (59/61)\u001b[K\rremote: Counting objects:  98% (60/61)\u001b[K\rremote: Counting objects: 100% (61/61)\u001b[K\rremote: Counting objects: 100% (61/61), done.\u001b[K\n","remote: Compressing objects:   2% (1/43)\u001b[K\rremote: Compressing objects:   4% (2/43)\u001b[K\rremote: Compressing objects:   6% (3/43)\u001b[K\rremote: Compressing objects:   9% (4/43)\u001b[K\rremote: Compressing objects:  11% (5/43)\u001b[K\rremote: Compressing objects:  13% (6/43)\u001b[K\rremote: Compressing objects:  16% (7/43)\u001b[K\rremote: Compressing objects:  18% (8/43)\u001b[K\rremote: Compressing objects:  20% (9/43)\u001b[K\rremote: Compressing objects:  23% (10/43)\u001b[K\rremote: Compressing objects:  25% (11/43)\u001b[K\rremote: Compressing objects:  27% (12/43)\u001b[K\rremote: Compressing objects:  30% (13/43)\u001b[K\rremote: Compressing objects:  32% (14/43)\u001b[K\rremote: Compressing objects:  34% (15/43)\u001b[K\rremote: Compressing objects:  37% (16/43)\u001b[K\rremote: Compressing objects:  39% (17/43)\u001b[K\rremote: Compressing objects:  41% (18/43)\u001b[K\rremote: Compressing objects:  44% (19/43)\u001b[K\rremote: Compressing objects:  46% (20/43)\u001b[K\rremote: Compressing objects:  48% (21/43)\u001b[K\rremote: Compressing objects:  51% (22/43)\u001b[K\rremote: Compressing objects:  53% (23/43)\u001b[K\rremote: Compressing objects:  55% (24/43)\u001b[K\rremote: Compressing objects:  58% (25/43)\u001b[K\rremote: Compressing objects:  60% (26/43)\u001b[K\rremote: Compressing objects:  62% (27/43)\u001b[K\rremote: Compressing objects:  65% (28/43)\u001b[K\rremote: Compressing objects:  67% (29/43)\u001b[K\rremote: Compressing objects:  69% (30/43)\u001b[K\rremote: Compressing objects:  72% (31/43)\u001b[K\rremote: Compressing objects:  74% (32/43)\u001b[K\rremote: Compressing objects:  76% (33/43)\u001b[K\rremote: Compressing objects:  79% (34/43)\u001b[K\rremote: Compressing objects:  81% (35/43)\u001b[K\rremote: Compressing objects:  83% (36/43)\u001b[K\rremote: Compressing objects:  86% (37/43)\u001b[K\rremote: Compressing objects:  88% (38/43)\u001b[K\rremote: Compressing objects:  90% (39/43)\u001b[K\rremote: Compressing objects:  93% (40/43)\u001b[K\rremote: Compressing objects:  95% (41/43)\u001b[K\rremote: Compressing objects:  97% (42/43)\u001b[K\rremote: Compressing objects: 100% (43/43)\u001b[K\rremote: Compressing objects: 100% (43/43), done.\u001b[K\n","Receiving objects:   0% (1/971)   \rReceiving objects:   1% (10/971)   \rReceiving objects:   2% (20/971)   \rReceiving objects:   3% (30/971)   \rReceiving objects:   4% (39/971)   \rReceiving objects:   5% (49/971)   \rReceiving objects:   6% (59/971)   \rReceiving objects:   7% (68/971)   \rReceiving objects:   8% (78/971)   \rReceiving objects:   9% (88/971)   \rReceiving objects:  10% (98/971)   \rReceiving objects:  11% (107/971)   \rReceiving objects:  12% (117/971)   \rReceiving objects:  13% (127/971)   \rReceiving objects:  14% (136/971)   \rReceiving objects:  15% (146/971)   \rReceiving objects:  16% (156/971)   \rReceiving objects:  17% (166/971)   \rReceiving objects:  18% (175/971)   \rReceiving objects:  19% (185/971)   \rReceiving objects:  20% (195/971)   \rReceiving objects:  21% (204/971)   \rReceiving objects:  22% (214/971)   \rReceiving objects:  23% (224/971)   \rReceiving objects:  24% (234/971)   \rReceiving objects:  25% (243/971)   \rReceiving objects:  26% (253/971)   \rReceiving objects:  27% (263/971)   \rReceiving objects:  28% (272/971)   \rReceiving objects:  29% (282/971)   \rReceiving objects:  30% (292/971)   \rReceiving objects:  31% (302/971)   \rReceiving objects:  32% (311/971)   \rReceiving objects:  33% (321/971)   \rReceiving objects:  34% (331/971)   \rReceiving objects:  35% (340/971)   \rReceiving objects:  36% (350/971)   \rReceiving objects:  37% (360/971)   \rReceiving objects:  38% (369/971)   \rReceiving objects:  39% (379/971)   \rReceiving objects:  40% (389/971)   \rReceiving objects:  41% (399/971)   \rReceiving objects:  42% (408/971)   \rReceiving objects:  43% (418/971)   \rReceiving objects:  44% (428/971)   \rReceiving objects:  45% (437/971)   \rReceiving objects:  46% (447/971)   \rReceiving objects:  47% (457/971)   \rReceiving objects:  48% (467/971)   \rReceiving objects:  49% (476/971)   \rReceiving objects:  50% (486/971)   \rReceiving objects:  51% (496/971)   \rReceiving objects:  52% (505/971)   \rReceiving objects:  53% (515/971)   \rReceiving objects:  54% (525/971)   \rReceiving objects:  55% (535/971)   \rReceiving objects:  56% (544/971)   \rReceiving objects:  57% (554/971)   \rReceiving objects:  58% (564/971)   \rReceiving objects:  59% (573/971)   \rReceiving objects:  60% (583/971)   \rReceiving objects:  61% (593/971)   \rReceiving objects:  62% (603/971)   \rReceiving objects:  63% (612/971)   \rReceiving objects:  64% (622/971)   \rReceiving objects:  65% (632/971)   \rReceiving objects:  66% (641/971)   \rReceiving objects:  67% (651/971)   \rReceiving objects:  68% (661/971)   \rReceiving objects:  69% (670/971)   \rReceiving objects:  70% (680/971)   \rReceiving objects:  71% (690/971)   \rReceiving objects:  72% (700/971)   \rReceiving objects:  73% (709/971)   \rReceiving objects:  74% (719/971)   \rReceiving objects:  75% (729/971)   \rReceiving objects:  76% (738/971)   \rReceiving objects:  77% (748/971)   \rReceiving objects:  78% (758/971)   \rReceiving objects:  79% (768/971)   \rReceiving objects:  80% (777/971)   \rReceiving objects:  81% (787/971)   \rReceiving objects:  82% (797/971)   \rReceiving objects:  83% (806/971)   \rReceiving objects:  84% (816/971)   \rReceiving objects:  85% (826/971)   \rReceiving objects:  86% (836/971)   \rReceiving objects:  87% (845/971)   \rReceiving objects:  88% (855/971)   \rReceiving objects:  89% (865/971)   \rReceiving objects:  90% (874/971)   \rReceiving objects:  91% (884/971)   \rReceiving objects:  92% (894/971)   \rReceiving objects:  93% (904/971)   \rremote: Total 971 (delta 33), reused 41 (delta 18), pack-reused 910\u001b[K\n","Receiving objects:  94% (913/971)   \rReceiving objects:  95% (923/971)   \rReceiving objects:  96% (933/971)   \rReceiving objects:  97% (942/971)   \rReceiving objects:  98% (952/971)   \rReceiving objects:  99% (962/971)   \rReceiving objects: 100% (971/971)   \rReceiving objects: 100% (971/971), 13.24 MiB | 52.36 MiB/s, done.\n","Resolving deltas:   0% (0/174)   \rResolving deltas:   5% (9/174)   \rResolving deltas:  21% (38/174)   \rResolving deltas:  22% (40/174)   \rResolving deltas:  23% (41/174)   \rResolving deltas:  29% (52/174)   \rResolving deltas:  31% (54/174)   \rResolving deltas:  32% (56/174)   \rResolving deltas:  33% (59/174)   \rResolving deltas:  34% (60/174)   \rResolving deltas:  35% (61/174)   \rResolving deltas:  36% (64/174)   \rResolving deltas:  37% (66/174)   \rResolving deltas:  39% (69/174)   \rResolving deltas:  55% (96/174)   \rResolving deltas:  61% (107/174)   \rResolving deltas:  68% (120/174)   \rResolving deltas:  69% (121/174)   \rResolving deltas:  70% (122/174)   \rResolving deltas:  79% (138/174)   \rResolving deltas:  86% (150/174)   \rResolving deltas:  89% (155/174)   \rResolving deltas:  91% (160/174)   \rResolving deltas:  93% (163/174)   \rResolving deltas:  94% (164/174)   \rResolving deltas:  95% (166/174)   \rResolving deltas:  96% (168/174)   \rResolving deltas:  97% (170/174)   \rResolving deltas:  98% (172/174)   \rResolving deltas: 100% (174/174)   \rResolving deltas: 100% (174/174), done.\n","Submodule 'face_toolbox_keras' (https://github.com/shaoanlu/face_toolbox_keras.git) registered for path 'face_toolbox_keras'\n","Cloning into '/content/fewshot-face-translation-GAN/face_toolbox_keras'...\n","remote: Enumerating objects: 43, done.        \n","remote: Counting objects:   2% (1/43)        \rremote: Counting objects:   4% (2/43)        \rremote: Counting objects:   6% (3/43)        \rremote: Counting objects:   9% (4/43)        \rremote: Counting objects:  11% (5/43)        \rremote: Counting objects:  13% (6/43)        \rremote: Counting objects:  16% (7/43)        \rremote: Counting objects:  18% (8/43)        \rremote: Counting objects:  20% (9/43)        \rremote: Counting objects:  23% (10/43)        \rremote: Counting objects:  25% (11/43)        \rremote: Counting objects:  27% (12/43)        \rremote: Counting objects:  30% (13/43)        \rremote: Counting objects:  32% (14/43)        \rremote: Counting objects:  34% (15/43)        \rremote: Counting objects:  37% (16/43)        \rremote: Counting objects:  39% (17/43)        \rremote: Counting objects:  41% (18/43)        \rremote: Counting objects:  44% (19/43)        \rremote: Counting objects:  46% (20/43)        \rremote: Counting objects:  48% (21/43)        \rremote: Counting objects:  51% (22/43)        \rremote: Counting objects:  53% (23/43)        \rremote: Counting objects:  55% (24/43)        \rremote: Counting objects:  58% (25/43)        \rremote: Counting objects:  60% (26/43)        \rremote: Counting objects:  62% (27/43)        \rremote: Counting objects:  65% (28/43)        \rremote: Counting objects:  67% (29/43)        \rremote: Counting objects:  69% (30/43)        \rremote: Counting objects:  72% (31/43)        \rremote: Counting objects:  74% (32/43)        \rremote: Counting objects:  76% (33/43)        \rremote: Counting objects:  79% (34/43)        \rremote: Counting objects:  81% (35/43)        \rremote: Counting objects:  83% (36/43)        \rremote: Counting objects:  86% (37/43)        \rremote: Counting objects:  88% (38/43)        \rremote: Counting objects:  90% (39/43)        \rremote: Counting objects:  93% (40/43)        \rremote: Counting objects:  95% (41/43)        \rremote: Counting objects:  97% (42/43)        \rremote: Counting objects: 100% (43/43)        \rremote: Counting objects: 100% (43/43), done.        \n","remote: Compressing objects: 100% (31/31), done.        \n","remote: Total 273 (delta 18), reused 29 (delta 11), pack-reused 230        \n","Receiving objects: 100% (273/273), 247.62 MiB | 38.49 MiB/s, done.\n","Resolving deltas: 100% (122/122), done.\n","Submodule path 'face_toolbox_keras': checked out 'fb472da7d6138845930bb86ca1993f5aaac6d78e'\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DeLjPws0HHU-","colab_type":"code","outputId":"6e5198bf-9564-4750-972f-378f2cf4628d","executionInfo":{"status":"ok","timestamp":1581977802586,"user_tz":-660,"elapsed":25598,"user":{"displayName":"Y Wang","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC_1743ZvXKz3VyvoMzNQtF6SVuixB99UzajSrbUg=s64","userId":"05996631538345338372"}},"colab":{"base_uri":"https://localhost:8080/","height":292}},"source":["# There are import errors under keras == 2.2.5\n","!pip install keras==2.2.4"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting keras==2.2.4\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/10/aa32dad071ce52b5502266b5c659451cfd6ffcbf14e6c8c4f16c0ff5aaab/Keras-2.2.4-py2.py3-none-any.whl (312kB)\n","\r\u001b[K     |█                               | 10kB 34.8MB/s eta 0:00:01\r\u001b[K     |██                              | 20kB 1.8MB/s eta 0:00:01\r\u001b[K     |███▏                            | 30kB 2.6MB/s eta 0:00:01\r\u001b[K     |████▏                           | 40kB 1.7MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 51kB 2.2MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 61kB 2.6MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 71kB 3.0MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 81kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 92kB 3.8MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 102kB 2.9MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 112kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 122kB 2.9MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 133kB 2.9MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 143kB 2.9MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 153kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 163kB 2.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 174kB 2.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 184kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 194kB 2.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 204kB 2.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 215kB 2.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 225kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 235kB 2.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 245kB 2.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 256kB 2.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 266kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 276kB 2.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 286kB 2.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 296kB 2.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 307kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 317kB 2.9MB/s \n","\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (2.8.0)\n","Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.0.8)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.12.0)\n","Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.4.1)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (3.13)\n","Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.17.5)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.1.0)\n","Installing collected packages: keras\n","  Found existing installation: Keras 2.2.5\n","    Uninstalling Keras-2.2.5:\n","      Successfully uninstalled Keras-2.2.5\n","Successfully installed keras-2.2.4\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ugeuo-e9lz-r","outputId":"c19f81d5-e9c9-461f-a925-27d6fe72a675","executionInfo":{"status":"ok","timestamp":1581977802587,"user_tz":-660,"elapsed":24085,"user":{"displayName":"Y Wang","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC_1743ZvXKz3VyvoMzNQtF6SVuixB99UzajSrbUg=s64","userId":"05996631538345338372"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["%cd \"fewshot-face-translation-GAN\""],"execution_count":3,"outputs":[{"output_type":"stream","text":["/content/fewshot-face-translation-GAN\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"qwFHol_plz_A","outputId":"478d2e64-b10c-4f16-8ead-18c39fdd217c","executionInfo":{"status":"ok","timestamp":1581977812314,"user_tz":-660,"elapsed":32221,"user":{"displayName":"Y Wang","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC_1743ZvXKz3VyvoMzNQtF6SVuixB99UzajSrbUg=s64","userId":"05996631538345338372"}},"colab":{"base_uri":"https://localhost:8080/","height":153}},"source":["# Download pre-trined weights\n","!gdown https://drive.google.com/uc?id=1DUMmZGTGKMyEYSKy-w34IDHawVF24rIs\n","!gdown https://drive.google.com/uc?id=1xl8cg7xaRnMsyiODcXguJ83d5hwodckB"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Downloading...\n","From: https://drive.google.com/uc?id=1DUMmZGTGKMyEYSKy-w34IDHawVF24rIs\n","To: /content/fewshot-face-translation-GAN/encoder.h5\n","6.26MB [00:00, 54.8MB/s]\n","Downloading...\n","From: https://drive.google.com/uc?id=1xl8cg7xaRnMsyiODcXguJ83d5hwodckB\n","To: /content/fewshot-face-translation-GAN/decoder.h5\n","124MB [00:00, 172MB/s]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"u9b2N8INnm8P","colab":{}},"source":["!mkdir weights\n","!mv decoder.h5 weights/decoder.h5\n","!mv encoder.h5 weights/encoder.h5"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"htzgMCcYlz_G"},"source":["## Load GAN model"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"PDCd3QM_lz_J","outputId":"bc058e5a-0c89-4cf8-b0c8-9afb023f1a42","executionInfo":{"status":"ok","timestamp":1581977829363,"user_tz":-660,"elapsed":46214,"user":{"displayName":"Y Wang","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC_1743ZvXKz3VyvoMzNQtF6SVuixB99UzajSrbUg=s64","userId":"05996631538345338372"}},"colab":{"base_uri":"https://localhost:8080/","height":525}},"source":["import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","from models import FaceTranslationGANInferenceModel\n","\n","model = FaceTranslationGANInferenceModel()"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4185: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n","\n","WARNING:tensorflow:From /content/fewshot-face-translation-GAN/networks/nn_blocks.py:141: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2018: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n","\n","Found checkpoints in weights folder. Built model with pre-trained weights.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"SQTAATsjlz_r"},"source":["## Load face-toolbox_keras"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"CpyAOeYXlz_w","outputId":"c6ad5ee4-c8f8-4cc2-a7e8-d839613147ec","executionInfo":{"status":"ok","timestamp":1581977879641,"user_tz":-660,"elapsed":94269,"user":{"displayName":"Y Wang","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC_1743ZvXKz3VyvoMzNQtF6SVuixB99UzajSrbUg=s64","userId":"05996631538345338372"}},"colab":{"base_uri":"https://localhost:8080/","height":275}},"source":["from face_toolbox_keras.models.verifier.face_verifier import FaceVerifier\n","fv = FaceVerifier(classes=512)\n","\n","from face_toolbox_keras.models.parser import face_parser\n","fp = face_parser.FaceParser()\n","\n","from face_toolbox_keras.models.detector import face_detector\n","fd = face_detector.FaceAlignmentDetector()\n","\n","from face_toolbox_keras.models.detector.iris_detector import IrisDetector\n","idet = IrisDetector()\n"],"execution_count":7,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","WARNING:tensorflow:From /content/fewshot-face-translation-GAN/face_toolbox_keras/models/verifier/face_verifier.py:52: The name tf.image.resize_bilinear is deprecated. Please use tf.compat.v1.image.resize_bilinear instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/image_ops_impl.py:1518: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Deprecated in favor of operator or tf.math.divide.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"s8rD90Ljlz_5"},"source":["## Translate faces and download generated image"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"PoFePLoelz__","colab":{}},"source":["import numpy as np\n","from utils import utils\n","from matplotlib import pyplot as plt\n","from google.colab import files"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PZR8BqBU3saB","colab_type":"code","colab":{}},"source":["# upload images to colab '/content/fewshot-face-translation-GAN' manually, as colab file upload fails often\n","fn_src = \"man1.jpg\"\n","fns_tar = [\"man2.jpg\"]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jsvnkbOW4gme","colab_type":"code","colab":{}},"source":["# run inferece code and download output images to local device\n","for i in range(len(fns_tar)):\n","  src, mask, aligned_im, (x0, y0, x1, y1), landmarks = utils.get_src_inputs(fn_src, fd, fp, idet)\n","  tar, emb_tar = utils.get_tar_inputs(fns_tar[i], fd, fv)\n","  out = model.inference(src, mask, tar, emb_tar)\n","  # cropped image of face area only\n","  result_face = np.squeeze(((out[0] + 1) * 255 / 2).astype(np.uint8))\n","  # assembled to original image\n","  result_img = utils.post_process_result(fn_src, fd, result_face, aligned_im, src, x0, y0, x1, y1, landmarks)\n","  name = fns_tar[i] + \"+ man1\" + \".png\"  # change \"man1\" to your src image name\n","  plt.imsave(name, result_img)\n","  files.download(name)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WMpNxQMTyo8k","colab_type":"code","colab":{}},"source":["# show generated image\n","\n","plt.imshow(result_img)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"c06fZ2j5MXzu","colab_type":"text"},"source":["## Download video from drive\n"]},{"cell_type":"code","metadata":{"id":"pA-D40LcMahT","colab_type":"code","outputId":"330efa40-f290-4f64-fdd5-d42766c754de","executionInfo":{"status":"ok","timestamp":1581977882713,"user_tz":-660,"elapsed":88292,"user":{"displayName":"Y Wang","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC_1743ZvXKz3VyvoMzNQtF6SVuixB99UzajSrbUg=s64","userId":"05996631538345338372"}},"colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["!gdown --id 1nDk821lAuxTM36P7ZB_BDGs1ql67Wzli"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Downloading...\n","From: https://drive.google.com/uc?id=1nDk821lAuxTM36P7ZB_BDGs1ql67Wzli\n","To: /content/fewshot-face-translation-GAN/jim_long_30fps.mov\n","\r0.00B [00:00, ?B/s]\r7.81MB [00:00, 68.4MB/s]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"g5CXSsixOS0Y","colab_type":"code","outputId":"fd84688c-1113-4b32-a29b-e8f2f5932fe0","executionInfo":{"status":"ok","timestamp":1581977885987,"user_tz":-660,"elapsed":90127,"user":{"displayName":"Y Wang","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC_1743ZvXKz3VyvoMzNQtF6SVuixB99UzajSrbUg=s64","userId":"05996631538345338372"}},"colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["!gdown --id 1-2scAAC4n5VRHq9GJrrVgR_8Yno0m8XE"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Downloading...\n","From: https://drive.google.com/uc?id=1-2scAAC4n5VRHq9GJrrVgR_8Yno0m8XE\n","To: /content/fewshot-face-translation-GAN/seth_long_30fps.mov\n","\r0.00B [00:00, ?B/s]\r4.67MB [00:00, 129MB/s]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"19TqoZUUoWE5","colab_type":"code","colab":{}},"source":["!mkdir pictures\n","!mkdir pictures/seth\n","!mkdir pictures/jim"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"D65oXr-tOGGF","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":683},"outputId":"e18d5ecf-f7ba-44d1-ae34-79d12d9917bf","executionInfo":{"status":"ok","timestamp":1581978003355,"user_tz":-660,"elapsed":205571,"user":{"displayName":"Y Wang","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC_1743ZvXKz3VyvoMzNQtF6SVuixB99UzajSrbUg=s64","userId":"05996631538345338372"}}},"source":["# extract frame from [seth.mov]\n","# runs slowly, please wait if you are testing our code\n","!ffmpeg -i seth_long_30fps.mov -vf fps=30 pictures/seth/seth%06d.png"],"execution_count":11,"outputs":[{"output_type":"stream","text":["ffmpeg version 3.4.6-0ubuntu0.18.04.1 Copyright (c) 2000-2019 the FFmpeg developers\n","  built with gcc 7 (Ubuntu 7.3.0-16ubuntu3)\n","  configuration: --prefix=/usr --extra-version=0ubuntu0.18.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --enable-gpl --disable-stripping --enable-avresample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librubberband --enable-librsvg --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-omx --enable-openal --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libopencv --enable-libx264 --enable-shared\n","  libavutil      55. 78.100 / 55. 78.100\n","  libavcodec     57.107.100 / 57.107.100\n","  libavformat    57. 83.100 / 57. 83.100\n","  libavdevice    57. 10.100 / 57. 10.100\n","  libavfilter     6.107.100 /  6.107.100\n","  libavresample   3.  7.  0 /  3.  7.  0\n","  libswscale      4.  8.100 /  4.  8.100\n","  libswresample   2.  9.100 /  2.  9.100\n","  libpostproc    54.  7.100 / 54.  7.100\n","Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'seth_long_30fps.mov':\n","  Metadata:\n","    major_brand     : qt  \n","    minor_version   : 512\n","    compatible_brands: qt  \n","    encoder         : Lavf57.83.100\n","  Duration: 00:00:43.97, start: 0.000000, bitrate: 848 kb/s\n","    Stream #0:0(eng): Video: h264 (High) (avc1 / 0x31637661), yuv420p, 1262x992 [SAR 1:1 DAR 631:496], 845 kb/s, 30 fps, 30 tbr, 15360 tbn, 60 tbc (default)\n","    Metadata:\n","      handler_name    : DataHandler\n","      encoder         : Lavc57.107.100 libx264\n","Stream mapping:\n","  Stream #0:0 -> #0:0 (h264 (native) -> png (native))\n","Press [q] to stop, [?] for help\n","Output #0, image2, to 'pictures/seth/seth%06d.png':\n","  Metadata:\n","    major_brand     : qt  \n","    minor_version   : 512\n","    compatible_brands: qt  \n","    encoder         : Lavf57.83.100\n","    Stream #0:0(eng): Video: png, rgb24, 1262x992 [SAR 1:1 DAR 631:496], q=2-31, 200 kb/s, 30 fps, 30 tbn, 30 tbc (default)\n","    Metadata:\n","      handler_name    : DataHandler\n","      encoder         : Lavc57.107.100 png\n","frame= 1319 fps= 12 q=-0.0 Lsize=N/A time=00:00:43.96 bitrate=N/A speed=0.406x    \n","video:1768691kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: unknown\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0JGQiznfLd6z","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":683},"outputId":"7de1a622-3c1f-4ea0-c109-28db14762e4f","executionInfo":{"status":"ok","timestamp":1581978078228,"user_tz":-660,"elapsed":275901,"user":{"displayName":"Y Wang","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC_1743ZvXKz3VyvoMzNQtF6SVuixB99UzajSrbUg=s64","userId":"05996631538345338372"}}},"source":["# extract frame from [jim.mov]\n","# runs slowly, please wait if you are testing our code\n","!ffmpeg -i jim_long_30fps.mov -vf fps=30 pictures/jim/jim%06d.png"],"execution_count":12,"outputs":[{"output_type":"stream","text":["ffmpeg version 3.4.6-0ubuntu0.18.04.1 Copyright (c) 2000-2019 the FFmpeg developers\n","  built with gcc 7 (Ubuntu 7.3.0-16ubuntu3)\n","  configuration: --prefix=/usr --extra-version=0ubuntu0.18.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --enable-gpl --disable-stripping --enable-avresample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librubberband --enable-librsvg --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-omx --enable-openal --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libopencv --enable-libx264 --enable-shared\n","  libavutil      55. 78.100 / 55. 78.100\n","  libavcodec     57.107.100 / 57.107.100\n","  libavformat    57. 83.100 / 57. 83.100\n","  libavdevice    57. 10.100 / 57. 10.100\n","  libavfilter     6.107.100 /  6.107.100\n","  libavresample   3.  7.  0 /  3.  7.  0\n","  libswscale      4.  8.100 /  4.  8.100\n","  libswresample   2.  9.100 /  2.  9.100\n","  libpostproc    54.  7.100 / 54.  7.100\n","Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'jim_long_30fps.mov':\n","  Metadata:\n","    major_brand     : qt  \n","    minor_version   : 512\n","    compatible_brands: qt  \n","    encoder         : Lavf57.83.100\n","  Duration: 00:00:43.33, start: 0.033008, bitrate: 1441 kb/s\n","    Stream #0:0(eng): Video: h264 (High) (avc1 / 0x31637661), yuv420p, 1470x992 [SAR 1:1 DAR 735:496], 1438 kb/s, 30 fps, 30 tbr, 15360 tbn, 60 tbc (default)\n","    Metadata:\n","      handler_name    : DataHandler\n","      encoder         : Lavc57.107.100 libx264\n","Stream mapping:\n","  Stream #0:0 -> #0:0 (h264 (native) -> png (native))\n","Press [q] to stop, [?] for help\n","Output #0, image2, to 'pictures/jim/jim%06d.png':\n","  Metadata:\n","    major_brand     : qt  \n","    minor_version   : 512\n","    compatible_brands: qt  \n","    encoder         : Lavf57.83.100\n","    Stream #0:0(eng): Video: png, rgb24, 1470x992 [SAR 1:1 DAR 735:496], q=2-31, 200 kb/s, 30 fps, 30 tbn, 30 tbc (default)\n","    Metadata:\n","      handler_name    : DataHandler\n","      encoder         : Lavc57.107.100 png\n","frame= 1300 fps= 18 q=-0.0 Lsize=N/A time=00:00:43.33 bitrate=N/A speed= 0.6x    \n","video:780987kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: unknown\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kc7nC9kIMD_p","colab_type":"code","colab":{}},"source":["#!pip install ffmpeg-python"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"S_SxhKDyl0AH"},"source":["## Translate faces for video"]},{"cell_type":"code","metadata":{"id":"fB-snv-Op7Mm","colab_type":"code","colab":{}},"source":["from utils import utils\n","import numpy as np\n","from matplotlib import pyplot as plt"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PqOedUhHKxYD","colab_type":"code","outputId":"dac441ae-e411-4a94-f0fd-458b21743736","executionInfo":{"status":"ok","timestamp":1581978374081,"user_tz":-660,"elapsed":671,"user":{"displayName":"Y Wang","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC_1743ZvXKz3VyvoMzNQtF6SVuixB99UzajSrbUg=s64","userId":"05996631538345338372"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["# add extracted image to lists\n","from PIL import Image\n","import glob\n","image_list_A = []\n","image_list_B = []\n","for filename in glob.glob('/content/fewshot-face-translation-GAN/pictures/jim/*.png'): #assuming png\n","    #im=Image.open(filename)\n","    image_list_A.append(filename)\n","\n","for filename in glob.glob('/content/fewshot-face-translation-GAN/pictures/seth/*.png'): #assuming png\n","    #im=Image.open(filename)\n","    image_list_B.append(filename)\n","\n","image_list_A.sort()\n","image_list_B.sort()\n","\n","print(len(image_list_A))\n","print(len(image_list_B))"],"execution_count":14,"outputs":[{"output_type":"stream","text":["1300\n","1319\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"CZn4KOgLtVnO","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"88a5cad7-0f42-4a1d-fb2f-8723c1f1d221","executionInfo":{"status":"ok","timestamp":1581978378089,"user_tz":-660,"elapsed":2854,"user":{"displayName":"Y Wang","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC_1743ZvXKz3VyvoMzNQtF6SVuixB99UzajSrbUg=s64","userId":"05996631538345338372"}}},"source":["!mkdir converted\n","%cd converted"],"execution_count":15,"outputs":[{"output_type":"stream","text":["/content/fewshot-face-translation-GAN/converted\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PDEW4oVfSCZF","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":473},"outputId":"eba9e431-97fe-4681-de22-1ec50edfb647","executionInfo":{"status":"error","timestamp":1581980021084,"user_tz":-660,"elapsed":1643231,"user":{"displayName":"Y Wang","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC_1743ZvXKz3VyvoMzNQtF6SVuixB99UzajSrbUg=s64","userId":"05996631538345338372"}}},"source":["# translating face frame by frame\n","# for a 30-fps video, you can see the result when having about 300 conveted video\n","# because of different number of frames of each video, loop might stop if listA size is smaller\n","\n","for i in range(len(image_list_B)):\n","  fns_tar = []\n","  fn_src = image_list_B[i]\n","  fns_tar.append(image_list_A[i])\n","  src, mask, aligned_im, (x0, y0, x1, y1), landmarks = utils.get_src_inputs(fn_src, fd, fp, idet)\n","  tar, emb_tar = utils.get_tar_inputs(fns_tar[0], fd, fv)\n","  out = model.inference(src, mask, tar, emb_tar)\n","  result_face = np.squeeze(((out[0] + 1) * 255 / 2).astype(np.uint8))\n","  result_img = utils.post_process_result(fn_src, fd, result_face, aligned_im, src, x0, y0, x1, y1, landmarks)\n","  name = \"%06d\"%i + \".png\"\n","\n","  plt.imsave(name, result_img)\n","\n"],"execution_count":16,"outputs":[{"output_type":"stream","text":["Building FAN for landmarks detection...\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n","WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n","Done.\n","Multiple faces detected. Only the most confident face will be processed.\n","Multiple faces detected. Only the most confident face will be processed.\n","Multiple faces detected. Only the most confident face will be processed.\n","Multiple faces detected. Only the most confident face will be processed.\n","Multiple faces detected. Only the most confident face will be processed.\n","Multiple faces detected. Only the most confident face will be processed.\n","Multiple faces detected. Only the most confident face will be processed.\n"],"name":"stdout"},{"output_type":"error","ename":"IndexError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-e00b98c597a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mfns_tar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mfn_src\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage_list_B\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   \u001b[0mfns_tar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_list_A\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m   \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maligned_im\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlandmarks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_src_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn_src\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mtar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memb_tar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tar_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfns_tar\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mIndexError\u001b[0m: list index out of range"]}]},{"cell_type":"code","metadata":{"id":"S9S04U-Phh_n","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":904},"outputId":"1477d7ee-652d-48e4-9d58-3b41ba1abb4e","executionInfo":{"status":"ok","timestamp":1581980670572,"user_tz":-660,"elapsed":35321,"user":{"displayName":"Y Wang","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC_1743ZvXKz3VyvoMzNQtF6SVuixB99UzajSrbUg=s64","userId":"05996631538345338372"}}},"source":["# generate result video, using converted photos\n","\n","!ffmpeg -framerate 30 -i %06d.png -vcodec libx264 -s 640x480 -pix_fmt yuv420p movie.mp4\n","\n","# you can download 'movie.mp4' once process finished\n","from google.colab import files\n","files.download('movie.mp4')"],"execution_count":18,"outputs":[{"output_type":"stream","text":["ffmpeg version 3.4.6-0ubuntu0.18.04.1 Copyright (c) 2000-2019 the FFmpeg developers\n","  built with gcc 7 (Ubuntu 7.3.0-16ubuntu3)\n","  configuration: --prefix=/usr --extra-version=0ubuntu0.18.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --enable-gpl --disable-stripping --enable-avresample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librubberband --enable-librsvg --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-omx --enable-openal --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libopencv --enable-libx264 --enable-shared\n","  libavutil      55. 78.100 / 55. 78.100\n","  libavcodec     57.107.100 / 57.107.100\n","  libavformat    57. 83.100 / 57. 83.100\n","  libavdevice    57. 10.100 / 57. 10.100\n","  libavfilter     6.107.100 /  6.107.100\n","  libavresample   3.  7.  0 /  3.  7.  0\n","  libswscale      4.  8.100 /  4.  8.100\n","  libswresample   2.  9.100 /  2.  9.100\n","  libpostproc    54.  7.100 / 54.  7.100\n","Input #0, image2, from '%06d.png':\n","  Duration: 00:00:43.33, start: 0.000000, bitrate: N/A\n","    Stream #0:0: Video: png, rgba(pc), 768x604 [SAR 3937:3937 DAR 192:151], 30 fps, 30 tbr, 30 tbn, 30 tbc\n","File 'movie.mp4' already exists. Overwrite ? [y/N] y\n","Stream mapping:\n","  Stream #0:0 -> #0:0 (png (native) -> h264 (libx264))\n","Press [q] to stop, [?] for help\n","\u001b[1;36m[libx264 @ 0x55b3ed55fe00] \u001b[0musing SAR=144/151\n","\u001b[1;36m[libx264 @ 0x55b3ed55fe00] \u001b[0musing cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n","\u001b[1;36m[libx264 @ 0x55b3ed55fe00] \u001b[0mprofile High, level 3.0\n","\u001b[1;36m[libx264 @ 0x55b3ed55fe00] \u001b[0m264 - core 152 r2854 e9a5903 - H.264/MPEG-4 AVC codec - Copyleft 2003-2017 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=3 lookahead_threads=1 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n","Output #0, mp4, to 'movie.mp4':\n","  Metadata:\n","    encoder         : Lavf57.83.100\n","    Stream #0:0: Video: h264 (libx264) (avc1 / 0x31637661), yuv420p, 640x480 [SAR 144:151 DAR 192:151], q=-1--1, 30 fps, 15360 tbn, 30 tbc\n","    Metadata:\n","      encoder         : Lavc57.107.100 libx264\n","    Side data:\n","      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: -1\n","frame= 1300 fps= 57 q=-1.0 Lsize=    1282kB time=00:00:43.23 bitrate= 242.8kbits/s speed=1.91x    \n","video:1265kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 1.270191%\n","\u001b[1;36m[libx264 @ 0x55b3ed55fe00] \u001b[0mframe I:6     Avg QP:17.74  size: 40763\n","\u001b[1;36m[libx264 @ 0x55b3ed55fe00] \u001b[0mframe P:339   Avg QP:20.52  size:  2351\n","\u001b[1;36m[libx264 @ 0x55b3ed55fe00] \u001b[0mframe B:955   Avg QP:27.66  size:   265\n","\u001b[1;36m[libx264 @ 0x55b3ed55fe00] \u001b[0mconsecutive B-frames:  0.6%  4.0%  0.9% 94.5%\n","\u001b[1;36m[libx264 @ 0x55b3ed55fe00] \u001b[0mmb I  I16..4:  5.5% 57.2% 37.3%\n","\u001b[1;36m[libx264 @ 0x55b3ed55fe00] \u001b[0mmb P  I16..4:  0.1%  0.6%  0.2%  P16..4: 22.1%  7.8%  5.9%  0.0%  0.0%    skip:63.2%\n","\u001b[1;36m[libx264 @ 0x55b3ed55fe00] \u001b[0mmb B  I16..4:  0.0%  0.1%  0.0%  B16..8: 11.0%  0.7%  0.1%  direct: 0.2%  skip:88.0%  L0:30.4% L1:65.6% BI: 3.9%\n","\u001b[1;36m[libx264 @ 0x55b3ed55fe00] \u001b[0m8x8 transform intra:60.8% inter:74.3%\n","\u001b[1;36m[libx264 @ 0x55b3ed55fe00] \u001b[0mcoded y,uvDC,uvAC intra: 79.6% 85.1% 66.9% inter: 3.3% 4.8% 0.3%\n","\u001b[1;36m[libx264 @ 0x55b3ed55fe00] \u001b[0mi16 v,h,dc,p: 51% 21%  7% 21%\n","\u001b[1;36m[libx264 @ 0x55b3ed55fe00] \u001b[0mi8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 28% 22% 11%  4%  6%  6%  7%  7%  8%\n","\u001b[1;36m[libx264 @ 0x55b3ed55fe00] \u001b[0mi4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 42% 19%  7%  4%  6%  6%  5%  6%  4%\n","\u001b[1;36m[libx264 @ 0x55b3ed55fe00] \u001b[0mi8c dc,h,v,p: 34% 24% 32%  9%\n","\u001b[1;36m[libx264 @ 0x55b3ed55fe00] \u001b[0mWeighted P-Frames: Y:0.0% UV:0.0%\n","\u001b[1;36m[libx264 @ 0x55b3ed55fe00] \u001b[0mref P L0: 70.9%  9.0% 15.7%  4.3%\n","\u001b[1;36m[libx264 @ 0x55b3ed55fe00] \u001b[0mref B L0: 90.9%  7.3%  1.8%\n","\u001b[1;36m[libx264 @ 0x55b3ed55fe00] \u001b[0mref B L1: 96.7%  3.3%\n","\u001b[1;36m[libx264 @ 0x55b3ed55fe00] \u001b[0mkb/s:239.11\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"drpzzGCgl0AW"},"source":["## Translate face and show generated results [original by author]"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"OGaNnRHkl0AX","outputId":"1d844b4d-1bea-469a-d2cf-ec30a81f8096","executionInfo":{"status":"error","timestamp":1581921158180,"user_tz":-660,"elapsed":2121,"user":{"displayName":"Y Wang","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC_1743ZvXKz3VyvoMzNQtF6SVuixB99UzajSrbUg=s64","userId":"05996631538345338372"}},"colab":{"base_uri":"https://localhost:8080/","height":300}},"source":["src, mask, aligned_im, (x0, y0, x1, y1), landmarks = utils.get_src_inputs(fn_src, fd, fp, idet)\n","tar, emb_tar = utils.get_tar_inputs(fns_tar, fd, fv)"],"execution_count":0,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-25-a57db805edd7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maligned_im\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlandmarks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_src_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn_src\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memb_tar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tar_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfns_tar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/fewshot-face-translation-GAN/utils/utils.py\u001b[0m in \u001b[0;36mget_src_inputs\u001b[0;34m(fn, fd, fp, idet)\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0mlandmarks\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mA\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0marray\u001b[0m \u001b[0mof\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m68\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;36m68\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mpoints\u001b[0m \u001b[0mface\u001b[0m \u001b[0mlandmarks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m     \"\"\"\n\u001b[0;32m--> 177\u001b[0;31m     \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m     \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mauto_resize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlandmarks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetect_face\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"]}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"qeleIZzwl0Ag","colab":{}},"source":["out = model.inference(src, mask, tar, emb_tar)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GbEqo4JJHHVY","colab_type":"code","colab":{}},"source":["# show input image\n","plt.figure()\n","plt.subplot(1,2,1)\n","plt.imshow(src)\n","plt.subplot(1,2,2)\n","plt.imshow(tar)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"q6ZJndRkHHVY","colab_type":"code","colab":{}},"source":["# show results\n","\n","result_face = np.squeeze(((out[0] + 1) * 255 / 2).astype(np.uint8))\n","plt.imshow(result_face)\n","\n","result_img = utils.post_process_result(fn_src, fd, result_face, aligned_im, src, x0, y0, x1, y1, landmarks)\n","plt.imshow(result_img)"],"execution_count":0,"outputs":[]}]}